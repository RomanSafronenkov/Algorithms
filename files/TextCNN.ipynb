{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef585027-4554-42b0-ab3d-9becb17ac8b3",
   "metadata": {},
   "source": [
    "# Convolutions in language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab52773-a87f-4295-9f59-0715384d6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union\n",
    "from IPython.display import HTML, clear_output\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54d9773e-7b33-438a-a8a8-1ecbb7a15db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./data/arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:128], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f59d2ce-0b65-4978-9c63-bd2a7019120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(lines)))\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print('num_tokens = ', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75d2a3c6-c114-43a1-99fb-949b14b1c2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'n': 1,\n",
       " 'm': 2,\n",
       " 'o': 3,\n",
       " '-': 4,\n",
       " 'D': 5,\n",
       " '@': 6,\n",
       " '~': 7,\n",
       " '\\\\': 8,\n",
       " '\\x7f': 9,\n",
       " 'r': 10,\n",
       " 'τ': 11,\n",
       " 'Y': 12,\n",
       " 'β': 13,\n",
       " '?': 14,\n",
       " '4': 15,\n",
       " 'é': 16,\n",
       " 'b': 17,\n",
       " 'χ': 18,\n",
       " 'B': 19,\n",
       " 'q': 20,\n",
       " 'H': 21,\n",
       " ':': 22,\n",
       " 'Ł': 23,\n",
       " 'u': 24,\n",
       " 'σ': 25,\n",
       " 'ő': 26,\n",
       " 'ö': 27,\n",
       " 'I': 28,\n",
       " 'ś': 29,\n",
       " 'L': 30,\n",
       " ']': 31,\n",
       " 'ã': 32,\n",
       " '|': 33,\n",
       " 'ç': 34,\n",
       " ',': 35,\n",
       " 'G': 36,\n",
       " 'α': 37,\n",
       " '^': 38,\n",
       " '°': 39,\n",
       " '{': 40,\n",
       " '$': 41,\n",
       " 'ä': 42,\n",
       " 'w': 43,\n",
       " ' ': 44,\n",
       " 'μ': 45,\n",
       " 'Σ': 46,\n",
       " \"'\": 47,\n",
       " 'F': 48,\n",
       " 'y': 49,\n",
       " 'h': 50,\n",
       " 'N': 51,\n",
       " '5': 52,\n",
       " 'à': 53,\n",
       " 'P': 54,\n",
       " 'p': 55,\n",
       " 'O': 56,\n",
       " 'J': 57,\n",
       " 's': 58,\n",
       " '>': 59,\n",
       " ';': 60,\n",
       " 'Z': 61,\n",
       " 'l': 62,\n",
       " 'R': 63,\n",
       " 'Q': 64,\n",
       " 'T': 65,\n",
       " '1': 66,\n",
       " '7': 67,\n",
       " 'ω': 68,\n",
       " '\\n': 69,\n",
       " 'λ': 70,\n",
       " 'ν': 71,\n",
       " 'γ': 72,\n",
       " 'g': 73,\n",
       " 'k': 74,\n",
       " '#': 75,\n",
       " 'ô': 76,\n",
       " 'C': 77,\n",
       " 'c': 78,\n",
       " '*': 79,\n",
       " '=': 80,\n",
       " 'j': 81,\n",
       " '6': 82,\n",
       " '<': 83,\n",
       " 'â': 84,\n",
       " 'W': 85,\n",
       " '_': 86,\n",
       " 'A': 87,\n",
       " 'i': 88,\n",
       " 'Ö': 89,\n",
       " 'æ': 90,\n",
       " '(': 91,\n",
       " 't': 92,\n",
       " '9': 93,\n",
       " 'í': 94,\n",
       " 'Ω': 95,\n",
       " 'v': 96,\n",
       " 'S': 97,\n",
       " 'f': 98,\n",
       " 'E': 99,\n",
       " '\"': 100,\n",
       " '&': 101,\n",
       " 'ρ': 102,\n",
       " '!': 103,\n",
       " '2': 104,\n",
       " 'É': 105,\n",
       " 'Ü': 106,\n",
       " '+': 107,\n",
       " 'ε': 108,\n",
       " 'X': 109,\n",
       " 'ü': 110,\n",
       " '[': 111,\n",
       " '`': 112,\n",
       " 'Π': 113,\n",
       " ')': 114,\n",
       " '3': 115,\n",
       " 'á': 116,\n",
       " 'K': 117,\n",
       " 'õ': 118,\n",
       " '%': 119,\n",
       " '8': 120,\n",
       " 'ï': 121,\n",
       " 'U': 122,\n",
       " 'x': 123,\n",
       " '/': 124,\n",
       " '0': 125,\n",
       " 'è': 126,\n",
       " 'ó': 127,\n",
       " 'M': 128,\n",
       " 'ê': 129,\n",
       " 'e': 130,\n",
       " 'V': 131,\n",
       " 'd': 132,\n",
       " '}': 133,\n",
       " 'z': 134,\n",
       " '.': 135}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b507c091-45d3-4c8a-a489-3a88edd406a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first=True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_ix = [token_to_id[c] for c in data[i]]\n",
    "        data_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a405fb8-4263-4a2b-b551-9e55c481e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(map(len, lines))\n",
    "sample = to_matrix(np.random.choice(lines, size=5), token_to_id, max_len=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfa1202a-0a0d-44d3-96f6-71d38b179ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        return self.forward(x, grad)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear3d(BaseLayer):\n",
    "    \"\"\"\n",
    "    Linear class permorms ordinary FC layer in neural networks\n",
    "    Parameters:\n",
    "    n_input - size of input neurons\n",
    "    n_output - size of output neurons\n",
    "    Methods:\n",
    "    set_optimizer(optimizer) - is used for setting an optimizer for gradient descent\n",
    "    forward(x) - performs forward pass of the layer\n",
    "    backward(output_error, learning_rate) - performs backward pass of the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_input: int, n_output: int) -> None:\n",
    "        super().__init__()\n",
    "        self.input = None\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.w = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(n_input, n_output))\n",
    "        self.b = np.random.normal(scale=np.sqrt(2 / (n_input + n_output)), size=(1, n_output))\n",
    "\n",
    "        self.w_optimizer = None\n",
    "        self.b_optimizer = None\n",
    "\n",
    "    def set_optimizer(self, optimizer) -> None:\n",
    "        self.w_optimizer = copy.copy(optimizer)\n",
    "        self.b_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.w_optimizer.set_weight(self.w)\n",
    "        self.b_optimizer.set_weight(self.b)\n",
    "\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        self.input = x\n",
    "        return np.matmul(x, self.w) + self.b  # the same as @\n",
    "\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        assert self.w_optimizer is not None and self.b_optimizer is not None, 'You should set an optimizer'\n",
    "        # перемножаем последние 2 измерения друг с другом с помощью matmul и суммируем\n",
    "        w_grad = np.sum(np.transpose(self.input, (0, 2, 1)) @ output_error, axis=0)\n",
    "        b_grad = np.sum(output_error, axis=(0, 1))\n",
    "        input_error = output_error @ self.w.T\n",
    "\n",
    "        self.w = self.w_optimizer.step(w_grad)\n",
    "        self.b = self.b_optimizer.step(b_grad)\n",
    "        return input_error\n",
    "\n",
    "\n",
    "class Activation(BaseLayer):\n",
    "    \"\"\"\n",
    "    Activation class is used for activation function of the FC layer\n",
    "    Params:\n",
    "    activation_function - activation function (e.g. sigmoid, RElU, tanh)\n",
    "    activation_derivative - derivative of the activation function\n",
    "    Methods:\n",
    "    forward(x) - performs forward pass of the layer\n",
    "    backward(output_error, learning_rate) - performs backward pass of the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, activation_function: callable, activation_derivative: callable) -> None:\n",
    "        super().__init__()\n",
    "        self.input = None\n",
    "        self.activation = activation_function\n",
    "        self.derivative = activation_derivative\n",
    "\n",
    "    def forward(self, x: np.array, grad: bool = True) -> np.array:\n",
    "        self.input = x\n",
    "        return self.activation(x)\n",
    "\n",
    "    def backward(self, output_error: np.array) -> np.array:\n",
    "        return output_error * self.derivative(self.input)\n",
    "\n",
    "class BaseOptimizer(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_weight(self, weight: np.array) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, grad: np.array) -> np.array:\n",
    "        pass\n",
    "\n",
    "class ADAM(BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam algorithm.\n",
    "\n",
    "    learning_rate (float, optional) – learning rate (default: 1e-3)\n",
    "    beta1, beta2 (Tuple[float, float], optional) –\n",
    "    coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "    eps (float, optional) – term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, beta1: float = 0.9, beta2: float = 0.999, eps: float = 1e-8,\n",
    "                 learning_rate: float = 3e-4, weight_decay: float = 0) -> None:\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.EMA1 = None\n",
    "        self.EMA2 = None\n",
    "\n",
    "        self.weight = None\n",
    "\n",
    "    def set_weight(self, weight: np.array) -> None:\n",
    "        self.weight = weight.copy()\n",
    "        self.EMA1 = np.zeros(shape=self.weight.shape)\n",
    "        self.EMA2 = np.zeros(shape=self.weight.shape)\n",
    "\n",
    "    def step(self, grad: np.array) -> np.array:\n",
    "        assert self.weight is not None, 'You should set the weight'\n",
    "        grad = grad.copy() + self.weight_decay * self.weight\n",
    "        self.EMA1 = (1 - self.beta1) * grad + self.beta1 * self.EMA1\n",
    "        self.EMA2 = (1 - self.beta2) * grad ** 2 + self.beta2 * self.EMA2\n",
    "        self.weight -= self.learning_rate * self.EMA1 / (np.sqrt(self.EMA2) + self.eps)\n",
    "\n",
    "        return self.weight.copy()\n",
    "\n",
    "class Embedding(BaseLayer):\n",
    "    def __init__(self, n_input, emb_dim, pad_idx=None):\n",
    "        self.n_input = n_input\n",
    "        self.emb_dim = emb_dim\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.weights = np.random.normal(scale=np.sqrt(2/(n_input+emb_dim)), size=(n_input, emb_dim))\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.weights_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.weights_optimizer.set_weight(self.weights)\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        self.input = x\n",
    "        return self.weights[x]\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        weights_grad = np.zeros_like(self.weights)\n",
    "        input_shape_len = len(self.input.shape)\n",
    "\n",
    "        if input_shape_len == 2:\n",
    "            for batch_n, s in enumerate(self.input):\n",
    "                for i, emb_i in enumerate(s):\n",
    "                    weights_grad[emb_i] += output_error[batch_n][i]\n",
    "\n",
    "        elif input_shape_len == 1:\n",
    "            for i, emb_i in enumerate(self.input):\n",
    "                weights_grad[emb_i] += output_error[i]\n",
    "\n",
    "        if self.pad_idx is not None:\n",
    "            weights_grad[self.pad_idx] = 0\n",
    "\n",
    "        self.weights = self.weights_optimizer.step(weights_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29b8d9e3-a32b-4f24-b06c-f99a1be0bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z: Union[np.array, float, int, list]) -> Union[np.array, float]:\n",
    "    \"\"\"\n",
    "    Tanh function\n",
    "    \"\"\"\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_derivative(z: Union[np.array, float, int, list]) -> Union[np.array, float]:\n",
    "    \"\"\"\n",
    "    Tanh function derivative\n",
    "    \"\"\"\n",
    "    return 1 - np.tanh(z) ** 2\n",
    "\n",
    "def sigmoid(z: Union[np.array, float, int, list]) -> Union[np.array, float]:\n",
    "    \"\"\"\n",
    "    Sigmoid function\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z: Union[np.array, float, int, list]) -> Union[np.array, float]:\n",
    "    \"\"\"\n",
    "    Sigmoid function derivative\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s * (1 - s)\n",
    "\n",
    "def softmax(z: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Softmax function\n",
    "    \"\"\"\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1, 1)\n",
    "\n",
    "def cross_entropy_loss(y_true: np.array, a_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    CrossEntropyLoss for multi-classification tasks\n",
    "    :param y_true: 2D vector with classes, i.e. [[0], [3], [4], [1], [2]]\n",
    "    :param a_pred: scores for each class before softmax function with shape [n_samples, n_classes]\n",
    "    :return: CrossEntropyLoss\n",
    "    \"\"\"\n",
    "    lenght_y = list(range(len(y_true)))\n",
    "    arg = -a_pred[lenght_y, y_true.ravel()]\n",
    "    sum_exp = np.sum(np.exp(a_pred), axis=1)\n",
    "    loss = np.sum(arg + np.log(sum_exp))\n",
    "    return loss / len(y_true)\n",
    "\n",
    "def cross_entropy_loss_derivative(y_true: np.array, a_pred: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    CrossEntropyLoss derivative for multi-classification tasks\n",
    "    :param y_true: 2D vector with classes, i.e. [[0], [3], [4], [1], [2]]\n",
    "    :param a_pred: scores for each class before softmax function with shape [n_samples, n_classes]\n",
    "    :return: np.array with shape [n_samples, n_classes] with CrossEntropyLoss derivatives for each weight\n",
    "    \"\"\"\n",
    "    lenght_y = list(range(len(y_true)))\n",
    "    sum_exp = np.sum(np.exp(a_pred), axis=1).reshape(-1, 1)\n",
    "    loss = np.exp(a_pred.copy()) / sum_exp\n",
    "    loss[lenght_y, y_true.ravel()] -= 1\n",
    "\n",
    "    return loss / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0ec2c5a-d556-4fb3-b1ed-aa812661e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(BaseLayer):\n",
    "    \"\"\"\n",
    "    Сверточный слой, со страйдом 1 и без паддингов, для батча\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        scale = np.sqrt(1/(in_channels*kernel_size))\n",
    "        self.kernel = np.random.uniform(-scale, scale, size=(out_channels, in_channels, kernel_size))\n",
    "        self.bias = np.random.uniform(-scale, scale, size=(out_channels))\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.kernel_optimizer = copy.copy(optimizer)\n",
    "        self.bias_optimizer = copy.copy(optimizer)\n",
    "\n",
    "        self.kernel_optimizer.set_weight(self.kernel)\n",
    "        self.bias_optimizer.set_weight(self.bias)\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        \"\"\"\n",
    "        Работает с битчами вида [BATCH_SIZE, SENTENCE_LEN, EMB_DIM]\n",
    "        \"\"\"\n",
    "        self.input = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.input_len = x.shape[1]\n",
    "        self.output_len = self.input_len - self.kernel_size + 1\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for sentence in x:\n",
    "            result.append(self._forward_for_one(sentence))\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    def _forward_for_one(self, x):\n",
    "        \"\"\"\n",
    "        Просто свертка для 1 предложения\n",
    "        \"\"\"\n",
    "        output = np.zeros(shape=(self.output_len, self.out_channels))\n",
    "\n",
    "        # для каждого выходного канала и ядра, отвечающего за этот канал\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            # по выходной длине\n",
    "            for i in range(self.output_len):\n",
    "                # умножаем срез по размеру ядра на ядро и суммируем\n",
    "                output[i:self.kernel_size+i, kernel_i] = self.bias[kernel_i] + np.sum(x[i:self.kernel_size+i, :] * ker.T)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        \"\"\"\n",
    "        Градиенты по всемy батчу\n",
    "        \"\"\"\n",
    "        dy_dkernels = []\n",
    "        dy_dbiass = []\n",
    "        dy_dxs = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            dy_dkernel, dy_dbias, dy_dx = self._calc_grad_for_one(output_error[i], self.input[i])\n",
    "            dy_dkernels.append(dy_dkernel)\n",
    "            dy_dbiass.append(dy_dbias)\n",
    "            dy_dxs.append(dy_dx)\n",
    "\n",
    "        dy_dkernels = np.sum(np.array(dy_dkernels), axis=0)  # суммируем градиенты по батчу\n",
    "        dy_dbiass = np.sum(np.array(dy_dbiass), axis=0)\n",
    "        dy_dxs = np.array(dy_dxs)\n",
    "\n",
    "        self.kernel = self.kernel_optimizer.step(dy_dkernels)  # делаем шаг спуска по сумме градиентов\n",
    "        self.bias = self.bias_optimizer.step(dy_dbiass)\n",
    "\n",
    "        return dy_dxs\n",
    "\n",
    "    def _calc_grad_for_one(self, output_error, x):\n",
    "        dy_dkernel = np.zeros(shape=self.kernel.shape)\n",
    "        dy_dbias = np.zeros(shape=self.bias.shape)\n",
    "        dy_dx = np.zeros(shape=x.shape)\n",
    "\n",
    "        for kernel_i, ker in enumerate(self.kernel):\n",
    "            helper_k = np.zeros(shape=ker.T.shape)\n",
    "\n",
    "            for i in range(self.output_len):\n",
    "                helper_k += x[i:self.kernel_size+i, :] * output_error[i, kernel_i]\n",
    "                dy_dx[i:self.kernel_size+i, :] += ker.T * output_error[i, kernel_i]\n",
    "\n",
    "            dy_dkernel[kernel_i] = helper_k.T\n",
    "            dy_dbias[kernel_i] = np.sum(output_error[:, kernel_i])\n",
    "\n",
    "        return dy_dkernel, dy_dbias, dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8eccf28-ecac-4a91-b4fc-f3521a2e985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, n_tokens=num_tokens, emb_size=16, hid_size=64):\n",
    "        self.emb = Embedding(n_tokens, emb_size)\n",
    "        self.conv = Conv1d(emb_size, hid_size, kernel_size=5)\n",
    "\n",
    "        self.padding_n = 4\n",
    "\n",
    "        self.classifier = Linear3d(hid_size, n_tokens)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.emb.set_optimizer(optimizer)\n",
    "        self.conv.set_optimizer(optimizer)\n",
    "        self.classifier.set_optimizer(optimizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, EMB_SIZE]\n",
    "        x = self.emb(x)\n",
    "\n",
    "        # [BATCH_SIZE, PADDING+SEQ_LEN, EMB_SIZE]\n",
    "        x = self.padding(x, self.padding_n)  # модель не должна смотреть в будущее для задачи LM\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, CHANNELS_OUT~HID_SIZE]\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # [BATCH_SIZE, SEQ_LEN, N_TOKENS]\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x # output tensor should be of shape [batch_size, sequence_length, n_tokens]\n",
    "\n",
    "    def padding(self, x, n):\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        padded_x = np.zeros(shape=(batch_size, seq_len+n, emb_dim))\n",
    "        padded_x[:, n:, :] = x\n",
    "        return padded_x\n",
    "\n",
    "    def backward(self, output_error):\n",
    "        output_error = self.classifier.backward(output_error)\n",
    "        output_error = self.conv.backward(output_error)\n",
    "\n",
    "        output_error = output_error[:, self.padding_n:, :]\n",
    "        self.emb.backward(output_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e86086fb-7dd2-4535-b2b6-d3f8283a6a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.set_optimizer(ADAM(learning_rate=0.001))\n",
    "\n",
    "batch_size = 64\n",
    "history = []\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(np.random.choice(lines, size=batch_size, replace=False), token_to_id, max_len=MAX_LENGTH)\n",
    "    \n",
    "    pred = cnn(batch_ix[:, :-1])\n",
    "\n",
    "    loss = 0\n",
    "    for t in range(batch_ix.shape[1]-1):\n",
    "        loss += cross_entropy_loss(batch_ix[:, t+1].reshape(-1, 1), pred[:, t, :])\n",
    "        \n",
    "    errors = np.zeros(shape=(batch_size, MAX_LENGTH-1, len(token_to_id)))\n",
    "    for t in range(errors.shape[1]-1):\n",
    "        errors[:, t, :] = cross_entropy_loss_derivative(batch_ix[:, t+1].reshape(-1, 1), pred[:, t, :])\n",
    "    \n",
    "    cnn.backward(errors)\n",
    "    \n",
    "    # visualizing training process\n",
    "    history.append(loss / batch_size)\n",
    "    if (i + 1) % 10 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"CNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b37df02e-7cc8-4492-98ef-1c8c34e8fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.534774300998044"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23fef4a9-e041-4173-82bf-a275fadb6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    phrase = copy.copy(seed_phrase)\n",
    "    \n",
    "    for t in range(len(seed_phrase)-1, max_length-len(seed_phrase)):\n",
    "        x_sequence = to_matrix([phrase], token_to_id, max_len=max_length)\n",
    "\n",
    "        pred = char_rnn(x_sequence)\n",
    "        probs = softmax(pred[:, t] / temperature).ravel()\n",
    "        next_ix = np.random.choice(len(tokens), p=probs)\n",
    "        phrase += tokens[next_ix]\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e94c6b69-8679-4706-8b83-a5ff80cba1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Admention ; Retication ; We pres ; We probestice s A A Senertion lation ; We pralis ; In thicy sed lation ; A Imale  Spareation t\n",
      " Aption ; We pronestion  for Fecentation ; The s and tivel ar bate Mation for Soppresing (DPercachis an dith  forecteration ation \n",
      " Reprode tenonn (MAd) in sof che s an  of amewitity ; Tha he probly for timation ; We probaltion ; Recters of Nenworks ; We propus\n",
      " Spaperation of the roplosing bation  forme the resul  and Opalition thapes on thes for arsiticalizy nor sed ce tor bation of Cont\n",
      " Astion ; We proret inate and Sentre pored for Splestar boded on ant of A pores for Sulter ingerint andical Intren l ardementrich \n",
      " Stement ; We presthe s al aring Apticapel ane weretive Con-bale the s the foridis  are perecting apprextine d Trestion ; The for \n",
      " Ant en whed Modeting ; In this of enter Bandurg ; We probule Forel fre tion ation lare phosessing  fer Sens ; In thes ; Fonditima\n",
      " Fraperat Network  formang for Semprous de send Vision tha for the thas fical ures bice Abess are medeling ant onver for this pape\n",
      " Instion  for Desprical on this andere than ; We praction A Sporeal setion ; We presenition  for Neural Mation of as ures ; In pro\n",
      " Constimation Ragus in  f Conder ang as ardica ; We problemation ar and Madion ; We probesing al trobine Netrol Sofica ion Spation\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(cnn, seed_phrase=' ', temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e26b46a2-1cd2-4668-b29d-b34b4cb90c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "div #notebook {\n",
       "    background-color: #FFF9EE;\n",
       "    margin: auto;\n",
       "}\n",
       "\n",
       "#notebook-container {\n",
       "    padding: 15px;\n",
       "    background-color: #FFFAFA;\n",
       "    min-height: 0;\n",
       "    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);\n",
       "    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);\n",
       "}\n",
       "\n",
       "div.cell { /* set cell width to about 80 chars */\n",
       "    background-color: #FFFAFA;\n",
       "}\n",
       "\n",
       "div.cell.border-box-sizing.code_cell.running { \n",
       "    border: 3px solid #111;\n",
       "}\n",
       "\n",
       "div.cell.code_cell {\n",
       "    background-color: #FFFAFA ;\n",
       "    border-radius: 5px;\n",
       "    padding: 1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Times New Roman';\n",
       "    color: #B8860B\n",
       "}\n",
       "\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-weight: 300;\n",
       "    font-size: 40pt;\n",
       "    line-height: 100%;\n",
       "    color: #8B4513;\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-weight: 700;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: #8B4513;\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-size: 25pt;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: #8B4513;\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-size: 20pt;\n",
       "    color: #8B4513;\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: #8B4513;\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: #8B4513;\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       ".text_cell_render p {\n",
       "    font-family: 'Times New Roman';\n",
       "    font-size: 15pt;\n",
       "    color: black;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       "mark {\n",
       "  background: #D5EAFF;\n",
       "  color: black;\n",
       "}\n",
       "\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:2000px;  /* your desired max-height here */\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    background-color: #FFFAFA;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./style.css') as f:\n",
    "    style = f.read()\n",
    "HTML(style)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yandex_nlp",
   "language": "python",
   "name": "yandex_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
